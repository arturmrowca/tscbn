from itertools import combinations
from time import clock

import matplotlib.pyplot as plt
import networkx as nx

from _include.m_utils.g_square_test import g_square_test
from _include.m_utils.prefix_tree import create_prefix_tree
from general.base import Base
from general.log import Log as L

class NovelStructureDiscoverer(Base):
    '''
    Interface defining structureDiscoverers
    '''

    def __init__(self, draw=False, filtering=True, min_out_degree=0.25, k_infrequent=0.1, alpha=0.1, max_reach=2, draw_only_result = False):
        '''
        :param draw: Set to True if graphs should be drawn after each step.
        :param filtering: Set to True if trie and DAWG should be filtered.
        :param min_out_degree: A node in the trie gets filtered when the sum of outgoing frequencies is smaller than
            min_out_degree times the incoming frequencies. This is necessary to assure a good transformation to the
            dawg. Example: A --100--> B --100--> C --1--> D, D will be filtered
        :param k_infrequent: An edge in the trie gets filtered when it appeared less than k_infrequent times the in
            frequencies of the node.
        :param alpha: Significance level used in the G^2 test.
        :param max_reach: Maximal size of the condition set in the PC algorithm like procedure.
        '''
        super(NovelStructureDiscoverer, self).__init__(visual = True)
        self.draw = draw
        self.filtering = filtering
        self.min_out_degree = min_out_degree
        self.k_infrequent = k_infrequent
        self.alpha = alpha
        self.max_reach = max_reach
        self.draw_only_result = draw_only_result

    def discover_structure(self, sequences, states_dict=None):
        '''
        This approach should discover the structure of a PGM. Returns a list of nodes and a list of edges.
        '''
        ping = clock()
        # eswv_es_map: map from event sequences with value to event sequences without value
        eswv_es_map, event_sequences, event_sequences_wv = self.create_ordered_event_sequences(sequences)
        # es_eswon_map: map from event sequences to event sequences with occurrence numbers
        max_pgm, es_eswon_map = self.create_maximal_pgm(event_sequences)
        event_sequences = self.add_occurrence_numbers_to_event_sequences(event_sequences_wv, eswv_es_map, es_eswon_map)
        execution_time = clock() - ping
        #L().log.info('---------------------------------------------------')
        #L().log.info('Time for creating maximal PGM: ' + str(execution_time))
        #L().log.info('---------------------------------------------------')
        ping = clock()
        pgm_structure = self.discover_structure_from_max_pgm(max_pgm, event_sequences)
        execution_time = clock() - ping
        #L().log.info('---------------------------------------------------------------')
        #L().log.info('Time for getting structure from maximal PGM: ' + str(execution_time))
        #L().log.info('---------------------------------------------------------------')
        self.data = []
        return pgm_structure.nodes, [list(edge) for edge in pgm_structure.edges]

    def create_maximal_pgm(self, sequences):
        '''
        Takes the event sequences as input and creates the maximal PGM. Additionally, the occurrence numbers are added
        to the sequences. Therefor, the map from sequences with value to sequences without value is required.
        '''
        dawg, paths = self.create_dawg(sequences)
        dawg_tc = self.transitive_closure(dawg)
        dawg_numbered, es_eswon_map = self.add_occurrence_numbers(dawg_tc, paths)
        max_pgm = self.compose_duplicated_nodes(dawg_numbered)
        return max_pgm, es_eswon_map

    def create_ordered_event_sequences(self, sequences):
        '''
        Takes the sequences as generated by the TSCBN structure generator and creates one
        ordered event sequence (with and without value and without timestamps) per sequence.
        Timestamps are not necessary for discovering the structure of the PGM.
        Example for a ordered event sequence: <(V0, o0_1), (V2, o2_0), (V1, o1_0), (V0, o0_0)>
        Example without value: <V0, V2, V1, V0>
        Returns a mapping from the event sequences with value to the ones without value and a list of event sequences
        without value (necessary to correctly determine the frequencies).
        '''
        ordered_event_sequences_map = {}  # surjective mapping from sequences with values to sequences without values
        ordered_event_sequences = []
        ordered_event_sequences_with_values = []
        for sequence in sequences:
            event_sequence = []
            event_sequence_with_values = []
            signal_event_number_dict = {}  # remember number of already added events
            number_of_events = 0  # total number of events over all signals
            for signal in sequence:
                signal_event_number_dict.update([(signal, 0)])
                number_of_events += len(sequence.get(signal))
            for _ in range(number_of_events):
                next_event = None  # next event to add the event sequence, determined by "smallest" timestamp
                next_signal = None  # remember signal next_event belongs to
                for signal in sequence:
                    event_number = signal_event_number_dict.get(signal)
                    if event_number >= len(sequence.get(signal)):
                        continue
                    event = sequence.get(signal)[event_number]
                    if event_number == 0 and event[1] != 0:  # first event does not start at timestamp 0
                        # TODO: append synthetic event for first interval (does this case appear???)
                        pass
                    if not next_event or event[1] < next_event[1]:  # check if timestamp is "smaller"
                        next_event = event
                        next_signal = signal
                    pass
                event_number = signal_event_number_dict.get(next_signal)
                event_number += 1
                signal_event_number_dict.update([(next_signal, event_number)])
                event_sequence.append(next_signal)  # append the signal that belongs to next_event
                event_sequence_with_values.append((next_signal, next_event[0]))  # append event with smallest timestamp
            ordered_event_sequences_map.update([(tuple(event_sequence_with_values), event_sequence)])
            ordered_event_sequences.append(event_sequence)
            ordered_event_sequences_with_values.append(event_sequence_with_values)
        return ordered_event_sequences_map, ordered_event_sequences, ordered_event_sequences_with_values

    def create_dawg(self, sequences):
        '''
        Takes the event sequences and creates the Directed Acyclic Word Graph (DAWG). Also known as
        Deterministic Acyclic Finite State Automaton (DAFSA) or Minimal Acyclic Deterministic Finite Automaton (MADFA).
        '''

        def filter_trie(trie):
            # check if all outgoing edges of a node have to be filtered (because it is the final node of many sequences)
            min_out_degree = self.min_out_degree
            k_infrequent = self.k_infrequent
            for node in nx.topological_sort(trie):
                signal = trie.nodes[node]['source']
                if signal == 'NIL':  # synthetic leaf node
                    continue
                in_edges = list(trie.in_edges(nbunch=node, data=True))
                out_edges = list(trie.out_edges(nbunch=node, data=True))
                frequency_in = sum(data['frequency'] for (_, _, data) in in_edges)
                frequency_out = sum(data['frequency'] for (_, _, data) in out_edges)
                # check if all out edges of a node have to be filtered (because it is the final node of many sequences)
                if 0 < frequency_out < min_out_degree * frequency_in:
                    #L().log.info('remove all outgoing edges of node ' + node + ' (frequency_in: ' + str(frequency_in) + ', frequency_out: ' + str(frequency_out) + ')')
                    # remove all descendants except NIL
                    trie.remove_edges_from([edge for edge in trie.out_edges(node) if edge[1] != 'NIL'])
                    continue
                pass
                # check if some single edges have to be filtered (because they are infrequent)
                if not signal:  # special case of root node
                    frequency_in = frequency_out
                for (u, v, data) in in_edges:  # filter incoming edges
                    if 0 < data['frequency'] < k_infrequent * frequency_out:
                        trie.remove_edge(u, v)
                        #L().log.info('remove incoming edge ' + str((u, v)) + ' to node ' + node + ' (frequency: ' + str(data['frequency']) + ', total frequency out: ' + str(frequency_out) + ')')
                        pass
                    pass
                for (u, v, data) in out_edges:  # filter outgoing edges
                    if 0 < data['frequency'] < k_infrequent * frequency_in:
                        trie.remove_edge(u, v)
                        #L().log.info('remove outgoing edge ' + str((u, v)) + ' from node ' + node + ' (frequency: ' + str(data['frequency']) + ', total frequency in: ' + str(frequency_out) + ')')
                        pass
                    pass
                pass
            assert nx.has_path(trie, root, 'NIL'), 'Too many edges filtered. No more path from start node to end node.'
            # remove nodes that are unreachable from root node or cannot reach the synthetic leaf node
            for node in list(trie.nodes):
                if not nx.has_path(trie, root, node) or not nx.has_path(trie, node, 'NIL'):
                    trie.remove_node(node)
                    #L().log.info('remove unreachable node ' + node)
                pass
            return trie

        trie, root = create_prefix_tree(sequences)  # create prefix tree, also called trie

        if self.draw and not self.draw_only_result:
            plt.title('Unfiltered trie with frequencies')
            signal_labels = nx.get_node_attributes(trie, 'source')
            frequencies = nx.get_edge_attributes(trie, 'frequency')
            pos = nx.spring_layout(trie)
            nx.draw(trie, pos=pos, labels=signal_labels)
            nx.draw_networkx_edge_labels(trie, pos=pos, labels=frequencies)
            plt.show()
        pass

        if self.filtering:
            trie = filter_trie(trie)
        pass

        if self.draw and not self.draw_only_result:
            plt.title('Filtered trie with frequencies')
            signal_labels = nx.get_node_attributes(trie, 'source')
            frequencies = nx.get_edge_attributes(trie, 'frequency')
            pos = nx.spring_layout(trie)
            nx.draw(trie, pos=pos, labels=signal_labels)
            nx.draw_networkx_edge_labels(trie, pos=pos, labels=frequencies)
            plt.show()
        pass

        prev_node = None  # remember previous node
        register = {}  # map subtree codes to nodes
        dawg = trie.copy()  # copy of trie will get modified during depth-first tree traversal
        for node in nx.dfs_postorder_nodes(trie, root):
            signal = trie.nodes[node]['source']  # get signal name that belongs to node
            if signal == 'NIL' or not signal:  # synthetic leaf node or root node
                continue
            # generate subtree code to detect similar subtrees
            if trie.has_edge(node, prev_node):
                subtree_code = signal + '*'
                for successor in [suc for suc in trie.successors(node) if suc != 'NIL']:
                    subtree_code += trie.nodes[successor]['subtree_code']
                subtree_code += '#'
            else:  # leaf node
                subtree_code = signal + '#'
            trie.nodes[node]['subtree_code'] = subtree_code
            #L().log.info('subtree code of node ' + node + ' is ' + subtree_code)
            if subtree_code not in register:  # first occurrence of this subtree
                register.update([(subtree_code, node)])
            else:  # subtree already in trie, merge nodes with similar subtree
                representative = register.get(subtree_code)
                #L().log.info('merge ' + node + ' and ' + representative + ' with subtree code ' + subtree_code)
                # store frequencies of outgoing edges of representative in dawg in dict
                out_edge_frequencies = dict([(dawg.nodes[v]['source'], data['frequency']) for (_, v, data)
                                             in dawg.out_edges(nbunch=representative, data=True)])
                dawg = nx.contracted_nodes(dawg, representative, node)
                for (_, v, data) in list(dawg.out_edges(nbunch=representative, data=True)):
                    signal = dawg.nodes[v]['source']
                    if not signal or signal == 'NIL':
                        continue
                    dawg.out_edges[representative, v]['frequency'] = \
                        data['frequency'] + out_edge_frequencies[signal]  # sum up frequencies of merged nodes
            prev_node = node
        pass

        # create list of all paths through DAWG
        paths = nx.all_simple_paths(dawg, root, 'NIL')

        if self.draw and not self.draw_only_result:
            plt.title('DAWG with frequencies')
            signal_labels = nx.get_node_attributes(dawg, 'source')
            frequencies = nx.get_edge_attributes(dawg, 'frequency')
            pos = nx.spring_layout(dawg)
            nx.draw(dawg, pos=pos, labels=signal_labels)
            nx.draw_networkx_edge_labels(dawg, pos=pos, labels=frequencies)
            plt.show()
        pass

        return dawg, paths

    def transitive_closure(self, dawg, markov=True):
        # TODO: markov=False yields errors in occurrence numbering
        '''
        Takes the DAWG and creates the transitive closure of the graph. Markov assumption states that occurrence i of
        signal v_j does not influence events after occurrence i+1 of the same signal v_j.
        '''
        dawg_tc = dawg.copy()
        for node in nx.topological_sort(dawg):
            signal = dawg.nodes[node]['source']
            if signal == 'NIL' or not signal:
                continue
            successors = [_ for _ in dawg.succ.get(node)]
            while successors:  # iterate over successors
                successor, *rest = successors
                if not successor == 'NIL':
                    dawg_tc.add_edge(node, successor)
                if not markov or not dawg.nodes[successor]['source'] == signal:
                    # different signal -> continue to search on this path
                    rest.extend([_ for _ in dawg.succ.get(successor)])
                successors = rest
            pass
        pass

        if self.draw and not self.draw_only_result:
            plt.title('DAWG with transitive closure')
            signal_labels = nx.get_node_attributes(dawg_tc, 'source')
            frequencies = nx.get_edge_attributes(dawg_tc, 'frequency')
            pos = nx.spring_layout(dawg_tc)
            nx.draw(dawg_tc, pos=pos, labels=signal_labels)
            nx.draw_networkx_edge_labels(dawg_tc, pos=pos, labels=frequencies)
            plt.show()
        pass

        return dawg_tc

    def add_occurrence_numbers(self, dawg, paths):
        '''
        Takes the DAWG and adds occurrence numbers to each of the nodes. This is done by topological sorting. If there
        are multiple occurrence numbers possible, then TODO: ...
        Also creates a mapping from event sequences without occurrence numbers to sequences with occurrence numbers.
        Therefor, information about all the paths in the DAWG is required.
        '''
        dawg_numbered = dawg.copy();
        for node in nx.topological_sort(dawg):
            signal = dawg_numbered.nodes[node]['source']
            if signal == 'NIL' or not signal:  # synthetic leaf node
                dawg_numbered.nodes[node]['complete_name'] = None
                continue
            predecessors = [pred for pred in list(dawg_numbered.pred.get(node)) if
                            dawg_numbered.nodes[pred]['source'] == signal]
            if not predecessors:
                dawg_numbered.nodes[node]['occurrence'] = 0
                dawg_numbered.nodes[node]['complete_name'] = signal + '_' + str(0)
                dawg_numbered.remove_edges_from(dawg.in_edges(nbunch=node))
                continue
            predecessor_occurrence_numbers = [dawg_numbered.nodes[predecessor]['occurrence'] for predecessor in
                                              predecessors]
            max_occurrence_number = max(predecessor_occurrence_numbers)
            dawg_numbered.nodes[node]['occurrence'] = max_occurrence_number + 1
            dawg_numbered.nodes[node]['complete_name'] = signal + '_' + str(max_occurrence_number + 1)
            #L().log.info('Complete Name of node ' + node + ' is ' + dawg_numbered.nodes[node]['complete_name'])
            if min(predecessor_occurrence_numbers) == max_occurrence_number:
                continue
            # TODO: handle the case when there are different occurrence numbers in the predecessors
            #L().log.info('different occurrence numbers in predecessors of node ' + node)
            for predecessor in predecessors:
                predecessor_occurrence_number = dawg_numbered.nodes[predecessor]['occurrence']
                if predecessor_occurrence_number < max_occurrence_number:
                    pass
                    # dawg.nodes[predecessor]['occurrence'] = range(predecessor_occurrence_number, max_occurrence_number)
                    # dawg.nodes[predecessor]['complete_name'] = signal + '_' + str(range(predecessor_occurrence_number, max_occurrence_number))
                    # TODO: handle this case (appears in real data)
                pass
            pass
        pass

        # create mapping from event sequences without occurrence numbers to sequences with occurrence numbers
        es_eswon_map = {}
        for path in paths:
            path_without_occurrences = []
            path_with_occurrences = []
            for node in path:
                signal = dawg_numbered.nodes[node]['source']
                if signal == 'NIL' or not signal:  # synthetic leaf node or root node
                    continue
                else:
                    path_without_occurrences.append(signal)
                    path_with_occurrences.append(signal + '_' + str(dawg_numbered.nodes[node]['occurrence']))
                pass
            es_eswon_map.update([(tuple(path_without_occurrences), path_with_occurrences)])
        pass

        if self.draw and not self.draw_only_result:
            plt.title('DAWG with occurrence numbers')
            signal_occurrence_labels = {}
            for node in dawg_numbered.nodes:
                label = str(dawg_numbered.nodes[node]['complete_name'])
                signal_occurrence_labels.update([(node, label)])
            pos = nx.spring_layout(dawg_numbered)
            nx.draw(dawg_numbered, pos=pos, labels=signal_occurrence_labels)
            plt.show()
        pass

        return dawg_numbered, es_eswon_map

    def compose_duplicated_nodes(self, dawg_numbered):
        '''
        Takes the numbered DAWG and merges all nodes corresponding to the same signal and occurrence number. This is
        done by relabeling the nodes to their complete_name. Networkx merges nodes automatically. Additionally,
        edges in strongly connected components are removed.
        '''
        dawg_numbered = nx.relabel_nodes(dawg_numbered, nx.get_node_attributes(dawg_numbered, 'complete_name'))
        dawg_numbered.remove_node(None)  # remove synthetic nodes

        max_pgm = dawg_numbered.copy()
        for scc in nx.strongly_connected_components(dawg_numbered):
            if len(scc) > 1:
                #L().log.info('remove edges in strongly connected component ' + str(scc))
                max_pgm.remove_edges_from(edge for edge in dawg_numbered.edges(nbunch=scc) if edge[1] in scc)
            pass
        pass
        # there should be no non-trivial strongly connected component anymore
        assert nx.number_strongly_connected_components(max_pgm) == len(max_pgm.nodes)
        return max_pgm

    def add_occurrence_numbers_to_event_sequences(self, event_sequences_wv, eswv_es_map, es_eswon_map):
        '''
        Takes the list of event sequences with value and the mapping from event sequences with value to the event
        sequences and the mapping from the event sequences to the event sequences with occurrence numbers to create
        and return all event sequences with values and occurrence numbers as required in the further steps of the
        structure discovery process.
        '''
        event_sequences = []
        for event_sequence_wv in event_sequences_wv:
            event_sequence = []
            es = eswv_es_map.get(tuple(event_sequence_wv))
            eswon = es_eswon_map.get(tuple(es))
            if not eswon:  # sequence was infrequent and filtered
                #L().log.info('event sequence ' + str(event_sequence_wv) + ' was infrequent')
                # TODO: trotzdem teilweise verwenden?
                continue
            for event, event_won in zip(event_sequence_wv, eswon):
                event_sequence.append((event_won, event[1]))
            event_sequences.append(event_sequence)
        return event_sequences

    def discover_structure_from_max_pgm(self, max_pgm, sequences):
        def markov_blanket(G, parent_node, node, include_other_temporal_nodes=False):
            '''
            Computes the Markov Blanket of node to determine the condition set for testing the edge parent_node -> node.
            :param include_other_temporal_nodes: If true then nodes of the same signal as node are not included in the
            markov blanket. # TODO: sinnvoll?
            '''

            def mb_node(include_other_temporal_nodes, pa, node, mb_candidate):
                return include_other_temporal_nodes or (G.nodes[node]['source'] != G.nodes[mb_candidate]['source']
                                                        and G.nodes[pa]['source'] != G.nodes[mb_candidate]['source'])

            mb = set(G.nodes[pa]['complete_name'] for pa in G.predecessors(node)
                     if mb_node(include_other_temporal_nodes, parent_node, node, pa))  # add parent nodes
            '''
            Any node is conditionally independent of its non-descendants given its direct parents
            mb |= set(G.nodes[ch]['complete_name'] for ch in G.successors(node)
                      if mb_node(include_other_temporal_nodes, parent_node, node, ch))  # add child nodes
            for child in G.successors(node):  # add parents of children
                mb |= set(G.nodes[pa]['complete_name'] for pa in G.predecessors(child)
                          if mb_node(include_other_temporal_nodes, parent_node, node, pa))
            '''
            if G.nodes[node]['complete_name'] in mb:  # remove node
                mb.remove(G.nodes[node]['complete_name'])
            if G.nodes[parent_node]['complete_name'] in mb:  # remove parent_node
                mb.remove(G.nodes[parent_node]['complete_name'])
            if None in mb:  # remove root node and synthetic leaf node
                mb.remove(None)
            return mb

        # parameters
        alpha = self.alpha
        max_reach = self.max_reach

        # procedure similar to PC algorithm
        pgm_structure = max_pgm.copy()
        condition_set_size = 0
        while True:
            cont = False
            remove_edges = []
            for (source_node, target_node) in pgm_structure.edges():
                source_signal = pgm_structure.nodes[source_node]['complete_name']
                target_signal = pgm_structure.nodes[target_node]['complete_name']
                if not source_signal or not target_signal:  # root node or synthetic leaf node
                    continue
                if pgm_structure.nodes[source_node]['source'] == pgm_structure.nodes[target_node][
                    'source']:  # TODO: Optimierung ok?
                    continue
                mb = markov_blanket(pgm_structure, target_node, source_node)  # TODO: Reihenfolge
                if len(mb) >= condition_set_size:
                    #L().log.info('testing ' + source_signal + ' --> ' + target_signal)
                    #L().log.info('markov blanket of ' + source_signal + ' is ' + str(mb))
                    for condition_set in combinations(mb, condition_set_size):
                        #L().log.info('independence test of ' + source_signal + ' and ' + target_signal + ' with subset ' + str(condition_set))
                        p_val = g_square_test(sequences, source_signal, target_signal, list(condition_set))
                        if p_val > alpha:
                            if pgm_structure.has_edge(source_node, target_node):
                                #L().log.info('remove edge ' + str((source_signal, target_signal)))
                                remove_edges.append((source_node, target_node))
                            break
                        pass
                    cont = True
                pass
            condition_set_size += 1
            pgm_structure.remove_edges_from(remove_edges)
            if cont is False:
                break
            if condition_set_size > max_reach:
                break

        if self.draw:
            plt.title('PGM after CI tests')
            signal_occurrence_labels = {}
            for node in pgm_structure.nodes:
                label = str(pgm_structure.nodes[node]['complete_name'])
                signal_occurrence_labels.update([(node, label)])
            pos = {}
            for node in pgm_structure.nodes:
                signal = pgm_structure.nodes[node]['source']
                if not signal:
                    x_coordinate = -1
                    y_coordinate = 1
                elif signal == 'NIL':
                    x_coordinate = 5.5
                    y_coordinate = 1.5
                else:
                    x_coordinate = 5.5
                    y_coordinate = 1.5
                pos.update([(node, [x_coordinate, y_coordinate])])
            nx.draw(pgm_structure, pos=pos, labels=signal_occurrence_labels)
            plt.show()
        pass

        return pgm_structure
